{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c096a4",
   "metadata": {},
   "source": [
    "# UK House Price Estimator - Model Training and Evaluation\n",
    "\n",
    "\n",
    "## Objective\n",
    "Train a regression model to estimate house prices and evaluate its performance.\n",
    "\n",
    "## Input\n",
    "- `HousePricesRecords_clean.csv`: Cleaned dataset with numeric and categorical features prepared.\n",
    "\n",
    "## Output\n",
    "- Trained regression model\n",
    "- Model evaluation metrics (e.g., MAE, RMSE)\n",
    "- Price prediction examples\n",
    "\n",
    "## Key Tasks\n",
    "- Encode categorical variables\n",
    "- Split the data into training and test sets\n",
    "- Train a regression model (e.g., Linear Regression)\n",
    "- Evaluate model accuracy using test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027f28d5",
   "metadata": {},
   "source": [
    "## Imports, Load & Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ed4b2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV      \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "df = pd.read_csv(\"../outputs/datasets/collection/HousePricesRecords_clean.csv\")\n",
    "y  = df[\"Price\"]\n",
    "X  = df.drop(columns=[\"Price\", \"Date of Transfer\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb11a767",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fe65159",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    \"Year\", \"Month\",\n",
    "    \"RegionMedianPrice\", \"RegionSaleCount\",\n",
    "    \"CountyMedianPrice\", \"CountySaleCount\"\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    \"Old/New\", \"Duration\",\n",
    "    \"Town/City\", \"County\", \"PPDCategory Type\",\n",
    "    \"Property_D\", \"Property_F\", \"Property_S\", \"Property_T\",\n",
    "    \"Region\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f769b74",
   "metadata": {},
   "source": [
    "## Filter Feature Lists to Available Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77d1c7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_features     = [c for c in numeric_features     if c in X.columns]\n",
    "categorical_features = [c for c in categorical_features if c in X.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4883f8",
   "metadata": {},
   "source": [
    "## Build Preprocessing & Modeling Pipeline\n",
    "\n",
    "Create a Scikit-learn pipeline that standardises numeric features and one-hot encodes categorical features, then fits a Random Forest regressor on the transformed data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db1d0083",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), numeric_features),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", RandomForestRegressor(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775c270f",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "Divide the dataset into training and testing subsets to evaluate model performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36608ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    random_state=42,  \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0b625a",
   "metadata": {},
   "source": [
    "## Define Hyperparameter Grid\n",
    "\n",
    "Specify the range of hyperparameters to explore for the `RandomForestRegressor` during hyperparameter tuning. These parameters control model complexity, tree depth, and randomness:\n",
    "\n",
    "- **`n_estimators`**: Number of trees in the forest.  \n",
    "- **`max_depth`**: Maximum depth of each tree (controls overfitting).  \n",
    "- **`min_samples_split`**: Minimum number of samples required to split an internal node.  \n",
    "- **`min_samples_leaf`**: Minimum number of samples required to be at a leaf node.  \n",
    "- **`max_features`**: Number of features to consider when looking for the best split.  \n",
    "- **`bootstrap`**: Whether bootstrap samples are used when building trees.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdb6a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"regressor__n_estimators\":      [100, 200, 300],\n",
    "    \"regressor__max_depth\":         [5, 10, 20],\n",
    "    \"regressor__min_samples_split\": [2, 5, 10],\n",
    "    \"regressor__min_samples_leaf\":  [1, 2, 4],\n",
    "    \"regressor__max_features\":      [\"sqrt\", \"log2\", None],\n",
    "    \"regressor__bootstrap\":         [True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300ffd6f",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with RandomizedSearchCV\n",
    "\n",
    "Configure a randomized search over the hyperparameter grid to find an optimal set of parameters for the `RandomForestRegressor` within the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0acc013f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "üîç Best params (random): {'regressor__n_estimators': 100, 'regressor__min_samples_split': 10, 'regressor__min_samples_leaf': 4, 'regressor__max_features': None, 'regressor__max_depth': 5, 'regressor__bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,\n",
    "    cv=3,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "print(\"üîç Best params (random):\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df13b042",
   "metadata": {},
   "source": [
    "## Verify All Features Are Numeric\n",
    "\n",
    "Identify any remaining non-numeric columns in the feature matrix `X`. Any columns listed here must be either encoded or removed before fitting the regression model to avoid errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bad588f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still non-numeric: ['Town/City', 'County', 'PPDCategory Type', 'Property_D', 'Property_F', 'Property_O', 'Property_S', 'Property_T', 'Region']\n"
     ]
    }
   ],
   "source": [
    "non_numeric = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "print(\"Still non-numeric:\", non_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2edc65e",
   "metadata": {},
   "source": [
    "## List Available Training Features\n",
    "\n",
    "Display all feature names in the training dataset (`X_train`) to verify which variables are being fed into the model after splitting and preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5512893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: ['Old/New', 'Duration', 'Town/City', 'County', 'PPDCategory Type', 'Year', 'Month', 'Property_D', 'Property_F', 'Property_O', 'Property_S', 'Property_T', 'Region', 'RegionMedianPrice', 'RegionSaleCount', 'CountyMedianPrice', 'CountySaleCount', 'LogPrice']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Available columns:\", X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523b38b7",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance on Test Set\n",
    "\n",
    "Use the trained pipeline (`best_model`) to predict prices for the held-out test set and compute key evaluation metrics:\n",
    "\n",
    "- **Mean Absolute Error (MAE):** Average absolute difference between predicted and actual prices.  \n",
    "- **Root Mean Squared Error (RMSE):** Square root of the average squared prediction errors, penalizing larger errors.  \n",
    "- **R¬≤ Score:** Proportion of variance in the target explained by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61ac655f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:  ¬£69,667\n",
      "Test RMSE: ¬£118,120\n",
      "Test R¬≤:   0.53\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test MAE:  ¬£{mae:,.0f}\")\n",
    "print(f\"Test RMSE: ¬£{rmse:,.0f}\")\n",
    "print(f\"Test R¬≤:   {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22ae3d8",
   "metadata": {},
   "source": [
    "## Save Evaluation Metrics\n",
    "\n",
    "Persist key model performance metrics to a JSON file for record-keeping and deployment dashboards.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44da6203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved metrics to outputs/models/metrics.json\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"../outputs/models\", exist_ok=True)\n",
    "metrics = {\"mae\": mae, \"rmse\": rmse, \"r2\": r2}\n",
    "with open(\"../outputs/models/metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics, f)\n",
    "\n",
    "print(\"Saved metrics to outputs/models/metrics.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f8d3c1",
   "metadata": {},
   "source": [
    "## Serialize Trained Model Pipeline\n",
    "\n",
    "Save the finalized machine learning pipeline so it can be loaded for inference or deployment without retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb9fb7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pipeline saved to ../outputs/models/house_price_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"../outputs/models\", exist_ok=True)\n",
    "joblib.dump(best_model, \"../outputs/models/house_price_pipeline.pkl\")\n",
    "print(\"‚úÖ Pipeline saved to ../outputs/models/house_price_pipeline.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
